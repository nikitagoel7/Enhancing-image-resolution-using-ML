{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.17"
    },
    "colab": {
      "name": "Learner_Notebook_Image_Super_Resolution-checkpoint.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNUFWhkbauEg",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://www.rhyme.com\"> <img src=\"https://www.rhyme.com/assets/img/logo-dark.png\" alt=\"Header\" style=\"width: 100px;\"/> </a>\n",
        "<h1 align=center> Image Super Resolution using Autoencoders</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9sBXkGxauEo",
        "colab_type": "text"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIldq00gauEq",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/pawankg/Enhancing-image-resolution-using-ML/blob/master/.ipynb_checkpoints/images/high_res_v_low_res.jpg?raw=1\" width=550px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz3Jzx0lauEu",
        "colab_type": "text"
      },
      "source": [
        "## Task 1: Project Overview and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTMQkrlBauEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import re\n",
        "from scipy import ndimage, misc\n",
        "from skimage.transform import resize, rescale\n",
        "from matplotlib import pyplot\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.layers import Conv2DTranspose, UpSampling2D, add\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX3U-ywtauFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_t4PaIWauFU",
        "colab_type": "text"
      },
      "source": [
        "## Task 2: What are Autoencoders?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBrCYWMiauFV",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/pawankg/Enhancing-image-resolution-using-ML/blob/master/.ipynb_checkpoints/images/autoencoder.jpg?raw=1\">\n",
        "Credit: Autoencoder Schema by <a href=\"https://blog.keras.io/img/ae/autoencoder_schema.jpg\">Francois Chollet, 2016</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKA1EFdyauFV",
        "colab_type": "text"
      },
      "source": [
        "<h4 align=center>Encoder Architecture</h4>\n",
        "<img src=\"https://github.com/pawankg/Enhancing-image-resolution-using-ML/blob/master/.ipynb_checkpoints/images/encoder.png?raw=1\" width=450px align=center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OXl9rF9auFW",
        "colab_type": "text"
      },
      "source": [
        "## Task 3: Build the Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnUyxcyZauFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_img = Input(shape=(256, 256, 3))\n",
        "# To fetch features from the input image\n",
        "l1 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(input_img)\n",
        "\n",
        "# 1 input layer - 2 convolution layer - 1 max pooling layer\n",
        "# Extracting features from a smaller image (i.e. after downscaling a picture to smaller dimension by a scale factor of 2) - applied on the output l1\n",
        "l2 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l1)\n",
        "\n",
        "# Max pooling layer\n",
        "l3 = MaxPooling2D(padding='same')(l2)\n",
        "\n",
        "# Add more convolution layer to learn more features\n",
        "l4 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l3)\n",
        "l5 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l4)\n",
        "l6 = MaxPooling2D(padding='same')(l5)\n",
        "l7 = Conv2D(256, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l6)\n",
        "encoder = Model(input_img, l7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9k-2jWPmauFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vEBYOsWauFd",
        "colab_type": "text"
      },
      "source": [
        "## Task 4: Build the Decoder to Complete the Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLirsuR1auFe",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://github.com/pawankg/Enhancing-image-resolution-using-ML/blob/master/.ipynb_checkpoints/images/decoder.png?raw=1\" width=450px>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyC-j-2vauFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_img = Input(shape=(256, 256, 3))\n",
        "# To fetch features from the input image\n",
        "l1 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(input_img)\n",
        "\n",
        "# 1 input layer - 2 convolution layer - 1 max pooling layer\n",
        "# Extracting features from a smaller image (i.e. after downscaling a picture to smaller dimension by a scale factor of 2) - applied on the output l1\n",
        "l2 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l1)\n",
        "\n",
        "# Max pooling layer\n",
        "l3 = MaxPooling2D(padding='same')(l2)\n",
        "\n",
        "# Add more convolution layer to learn more features\n",
        "l4 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l3)\n",
        "l5 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l4)\n",
        "l6 = MaxPooling2D(padding='same')(l5)\n",
        "l7 = Conv2D(256, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na0rR839auFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decoder - to take input representation and scale it by 2X\n",
        "\n",
        "l8 = UpSampling2D()(l7)\n",
        "l9 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l8)\n",
        "l10 = Conv2D(128, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l9)\n",
        "l11 = add([l5, l10])\n",
        "l12 = UpSampling2D()(l11)\n",
        "l13 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l12)\n",
        "l14 = Conv2D(64, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l13)\n",
        "l15 = add([l14, l2])\n",
        "\n",
        "decoded = Conv2D(3, (3, 3), padding='same', activation='relu', activity_regularizer=regularizers.l1(10e-10))(l15)\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.summary()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiX2ThXiauFp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OOREjJdauFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogiM10xHauFu",
        "colab_type": "text"
      },
      "source": [
        "## Task 5: Create Dataset and Specify Training Routine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "X7wSgmAnauFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batches(just_load_dataset=False):\n",
        "\n",
        "    batches = 256 \n",
        "\n",
        "    batch = 0 \n",
        "    batch_nb = 0 \n",
        "    max_batches = -1 \n",
        "    \n",
        "    ep = 4 \n",
        "\n",
        "    images = []\n",
        "    x_train_n = []\n",
        "    x_train_down = []\n",
        "    \n",
        "    x_train_n2 = [] \n",
        "    x_train_down2 = []\n",
        "    \n",
        "    for root, dirnames, filenames in os.walk(\"/home/rhyme/Desktop/Project/data/cars_train\"):\n",
        "        for filename in filenames:\n",
        "            if re.search(\"\\.(jpg|jpeg|JPEG|png|bmp|tiff)$\", filename):\n",
        "                if batch_nb == max_batches: \n",
        "                    return x_train_n2, x_train_down2\n",
        "                filepath = os.path.join(root, filename)\n",
        "                image = pyplot.imread(filepath)\n",
        "                if len(image.shape) > 2:\n",
        "                        \n",
        "                    image_resized = resize(image, (256, 256))\n",
        "                    x_train_n.append(image_resized)\n",
        "                    x_train_down.append(rescale(rescale(image_resized, 0.5), 2.0))\n",
        "                    batch += 1\n",
        "                    if batch == batches:\n",
        "                        batch_nb += 1\n",
        "\n",
        "                        x_train_n2 = np.array(x_train_n)\n",
        "                        x_train_down2 = np.array(x_train_down)\n",
        "                        \n",
        "                        if just_load_dataset:\n",
        "                            return x_train_n2, x_train_down2\n",
        "                        \n",
        "                        print('Training batch', batch_nb, '(', batches, ')')\n",
        "\n",
        "                        autoencoder.fit(x_train_down2, x_train_n2,\n",
        "                            epochs=ep,\n",
        "                            batch_size=10,\n",
        "                            shuffle=True,\n",
        "                            validation_split=0.15)\n",
        "                    \n",
        "                        x_train_n = []\n",
        "                        x_train_down = []\n",
        "                    \n",
        "                        batch = 0\n",
        "\n",
        "    return x_train_n2, x_train_down2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv0M3VHFauFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wHfwu9OauF3",
        "colab_type": "text"
      },
      "source": [
        "## Task 6: Load the Dataset and Pre-trained Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyrkIp-kauF4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_n, x_train_down = train_batches(just_load_dataset=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7GhjrmGauF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "autoencoder.load_weights('sr.img_net.mse.final_model5.no_patch.weights.best.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGsLisoJauF-",
        "colab_type": "text"
      },
      "source": [
        "## Task 7: Model Predictions and Visualizing the Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCPMUgUhauF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder.load_weights('encoder_weights.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y7k6OWeauGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_imgs = encoder.predict(x_train_down)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7bpgnpFauGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_imgs.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ1segV1auGK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sr1 = np.clip(autoencoder.predict(x_train_down), 0.0, 1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc2edvR0auGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_index = 251 # np.random.randint(0, 256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yGhxDMjauGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(128, 128))\n",
        "i = 1\n",
        "ax = plt.subplot(10, 10, i)\n",
        "plt.imshow(x_train_down[image_index])\n",
        "i += 1\n",
        "\n",
        "ax = plt.subplot(10, 10, i)\n",
        "plt.imshow(x_train_down[image_index], interpolation='bicubic')\n",
        "i += 1\n",
        "\n",
        "ax = plt.subplot(10, 10, i)\n",
        "plt.imshow(encoded_imgs[image_index].reshape((64*64, 256)))\n",
        "i += 1\n",
        "\n",
        "ax = plt.subplot(10, 10, i)\n",
        "plt.imshow(sr1[image_index])\n",
        "i += 1\n",
        "\n",
        "ax = plt.subplot(10, 10, i)\n",
        "plt.imshow(X_train_n[image_index])\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_84e4URauGU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}